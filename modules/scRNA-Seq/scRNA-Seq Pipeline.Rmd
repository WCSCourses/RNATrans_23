---
title: "Single cell data analysis - RNA Transcriptomics"
author: "Badran Elshenawy"
output: 
  html_document:
    toc: true
    toc_depth: 2
---

# Overview

-   In this practical session, we are going to analyse the data generated by the single cell experiment. The aim of this session is go through the fundamental steps of a standardized pipeline, which which involves the following:

    -   **Quality Control (QC):** This is the first step of every scRNA-Seq pipeline, and it is vital to ensure the quality of the data for subsequent processing steps in the pipeline. QC is divided into the following:

        -   **Cell QC:** This is QC done to filter out low-quality cells that represent either broken droplets with no cells or doublets. This is done based on key QC metrics, namely library size, total detected features, and percentage mitochondrial genes.

        -   **Gene QC:** This is QC done to filter out features with very low levels of the expression in the data that could skew the variability analysis and dimensionality reduction.

    -   **Normalisation & Variable Feature Detection:** This is the next step in the pipeline, and it is crucial for adjusting the count matrix to adjust for differences in library size between the different cells as well as identifying the genes with the highest levels of variation relative to the mean expression; hypervariable features are likely to represent the primary sources of variation in the data (both biological and technical), and so their identification is key for subsequent dimensionality reduction and clustering in the single cell pipeline.

    -   **Cell Cycle Scoring:** Cell cycle is a major source of variation in transcriptomics data, and the aim of this step is to uncover the effects of cell cycle on the biological variation of the data.

    -   **Dimensionality Reduction & Visualisation:** Dimensionality reduction is vital for reducing the complexity of the data to allow for effective visualisation and exploration of sources of variation in the data. The two primary forms of dimensionality reduction used in this pipeline are PCA and UMAP.

    -   **Differential Expression Analysis:** Differential expression analysis is vital for identifying key marker features for groups of interest in the data. In this guide, we will be doing DEA between cells captured for WT and scrambled

-   We further recommend the following online resources for single cell RNA-seq analysis:

    -   <https://satijalab.org/seurat/>

    -   <https://scrnaseq-course.cog.sanger.ac.uk/website/index.html>

# R Markdown setup

```{r setup, include=FALSE}
root.directory <- dirname(rstudioapi::getActiveDocumentContext()$path)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
knitr::opts_knit$set(root.dir = root.directory)

options(stringsAsFactors = FALSE)
```

# Packages

-   In this tutorial, we are going to use two primary packages:

    -   **`Tidyverse`:** this is a very popular system of packages in R that facilitates common data science operations involving data wrangling and visualisations. If you would like to learn more about the tidyverse in general, please check [**here**](https://www.r-bloggers.com/2020/06/a-very-short-introduction-to-tidyverse/). For more comprehensive coverage of the system, please check [**here**](https://r4ds.had.co.nz/).

    -   **`Seurat`:** this is the state--of-art package for analysis of single cell RNA-Seq data, and this is what we will be using here for the processing and and manipulation of single cell data. For more information about additional functionality that the package offers, please check the documentation (easily accessible through R) as well as the [**official vignettes**](https://satijalab.org/seurat/articles/get_started.html).

-   The final command below sets the directory this file is in to be the active directory for this session. This is crucial for the ***read*** and ***write*** functions below to work effectively since they use relative rather than absolute filepaths (if you are not sure what the difference between relative and absolute filepaths is, please check [**here**](https://www.codingrooms.com/blog/file-paths#:~:text=A%20relative%20path%20describes%20the,regularly%20use%20relative%20file%20paths.)).

```{r warning=FALSE}
# Package Installation
install.packages(c("tidyverse","Seurat", "SCpubr"))
BiocManager::install("scater")

# Packages
suppressMessages(library(tidyverse))
suppressMessages(library(Seurat))
suppressMessages(library(SCpubr))
suppressMessages(library(scater))

#Setting Working Directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

# 1. Data Import

-   The first step is data import:

    -   There are six folder corresponding to the six samples used in this experiment (WT,MIX SCRAM; two for each of the conditions).

    -   Within each folder there is an expression matrix created by [**Cell Ranger**](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/what-is-cell-ranger). We are going to focus on the `filtered_gene_bc_matrices`. This is the expression matrix in sparse matrix format.

        -   The data **(matrix.mtx)** are saved separately from the the gene names **(genes.tsv)** and the barcodes **(barcodes.tsv).**

-   The import of the data below is done using Seurat's `Read10X()` function.

```{r}
# WT
wt1 <- Read10X(data.dir = "../../course_data//scRNA-Seq Module/WTAC_SCRNA8012500/filtered_feature_bc_matrix/")
# wt2 <- Read10X(data.dir = "../../course_data//scRNA-Seq Module/WTAC_SCRNA8012501/filtered_feature_bc_matrix/")

# Scrambled
scr1 <- Read10X(data.dir = "../../course_data//scRNA-Seq Module/WTAC_SCRNA8012504/filtered_feature_bc_matrix/")
scr2 <- Read10X(data.dir = "../../course_data//scRNA-Seq Module/WTAC_SCRNA8012505/filtered_feature_bc_matrix/")
```

-   **Note:** The WT2 sample contained four times more cells than we expected and lower number of counts per cell. We don't include it in this analysis, but it can be used independently to validate our conclusions from this analysis.

## Merging samples

-   Here, we are merge the three samples (WT1, SCR1, SCR2) into one expression matrix. We add the sample of origin in each of the cells, so that later we can retrieve the information.

```{r}
# WT
w1 <- as.matrix(wt1)
colnames(w1) <- paste(colnames(w1),"w1", sep = "_")
# w2 <- as.matrix(wt2)
# colnames(w2) <- paste(colnames(w2),"w2", sep = "_")

# Scrambled
s1 <- as.matrix(scr1)
colnames(s1) <- paste(colnames(s1),"s1", sep = "_")
s2 <- as.matrix(scr2)
colnames(s2) <- paste(colnames(s2),"s2", sep = "_")

# cbind
x <- cbind(w1, s1, s2)

# we remove these file to save memory.
rm(w1, wt1, s1, scr1, s2, scr2)
```

# 2. Seurat Object Instantiation

-   The next step here is the creation of a seurat object with the merged counts. This is done using `CreateSeuratObject()`, and it takes as input the merged count matrix `x` and a project name.

-   The creation of the seurat object automatically calculates library size and total number of detected features per cell and adds these to the seurat object metadata, which is accessible below through `seu@meta.data`. These metrics are key for the upcoming QC step.

-   The next step here is the calculation of the percentage of counts attributed to mitochondrial genes. This is another important QC metric.

```{r}
# Seurat Object Instantiation
seu <- CreateSeuratObject(counts = x, project = "RNA-transcriptomics")

# Batch & Condition Annotation
seu$batch <- str_split(string = colnames(seu),pattern = "_",simplify = T)[,2]
seu$condition <- ifelse(seu$batch == "w1",yes = "WT",no = "SCRAMBLED")

# Mitochondrial Genes Percentage Quantification
seu[["percent.mt"]] <- PercentageFeatureSet(seu, pattern = "^mt-")

# Seurat Object Metadata Exploration
view(seu@meta.data)
```

# 3. QC

## 3.1 Cell QC

-   Single cell QC is done using 3 core metrics:

    -   **Library Size/Total Counts**: Total number of counts per cell for all the features.

    -   **Total Features:** Total number of unique non-zero features per cell.

    -   **Mitochondrial Genes Percentage:** Percentage of a cell's total counts that is dominated by mitochondrial genes.

-   For library size and total features, the aim is to remove cells with very low or very high values; the underlying assumption here is that cells with low counts and features represent broken droplets that have been broken and have thus failed to capture a cell. On the other hand, cells with high counts and features probably represent doublets or multiplets.

    -   There are specific R/Python packages that can be used to detect doublets, e.g. [**Scrublet**](https://www.sciencedirect.com/science/article/pii/S2405471218304745) or [**DoubletFinder**](https://www.sciencedirect.com/science/article/pii/S2405471219300730).

-   For mitochondrial genes percentage, mitochondrial gene expression should not be detected in single cell data unless there is significant mitochondrial permeation and leakage of mitochondrial genes into the cytoplasm, which is indicative of cell stress and cell death (both apoptotic and necrotic). Cells with high percentages of mitochondrial genes in their counts are probably stressed cells that are not representative of the biological variation of interest and are best removed from the data.

-   Defining threshold values for QC is done empirically after inspecting the distributions of total counts and total features; this is best done using key visualisations, namely histograms, violin plots, and scatter plots.

    -   Here, we can use the Median Absolute Deviation **([MAD](https://en.wikipedia.org/wiki/Median_absolute_deviation))** for guidance.

### 3.1.1. Library Size

```{r, fig.height= 4, fig.width= 4}
# Violin Plot
VlnPlot(object = seu,
        features = "nCount_RNA",
        group.by = "condition")

# MAD Thresholds
outlier_counts <- isOutlier(metric = seu@meta.data$nCount_RNA,
          nmads = 3,
          log = T)
counts_thresholds <- attr(outlier_counts, "thresholds")

# Histogram
seu@meta.data %>% ggplot(aes(x = nCount_RNA)) + 
  geom_histogram(aes(fill = condition)) + labs(x = "Library Size", 
                                               y = "Frequency",
                                               title = "Library Size Histogram") + 
  facet_grid(condition ~ .) + geom_vline(xintercept = counts_thresholds)
```

### 3.1.2. Total features

```{r, fig.height=4, fig.width=4}
# Violin Plot
VlnPlot(object = seu,
        features = "nFeature_RNA",
        group.by = "condition")

# MAD Thresholds
outlier_features <- isOutlier(metric = seu@meta.data$nFeature_RNA,
          nmads = 3,
          log = T)
features_thresholds <- attr(outlier_features, "thresholds")

# Histogram
seu@meta.data %>% ggplot(aes(x = nFeature_RNA)) + 
  geom_histogram(aes(fill = condition)) + labs(x = "Total Features", 
                                               y = "Frequency",
                                               title = "Total Features Histogram") +
  facet_grid(condition ~ .) + geom_vline(xintercept = features_thresholds)
```

### 3.1.3. Percentage Mitochondrial Genes

```{r, fig.height=4, fig.width=4}
# Violin Plot
VlnPlot(object = seu,
        features = "percent.mt",
        group.by = "condition")

# Histogram
seu@meta.data %>% ggplot(aes(x = percent.mt)) + 
  geom_histogram(aes(fill = condition)) + labs(x = "% Mitochondrial Genes", 
                                               y = "Frequency",
                                               title = "% Mitocondrial Features Histogram") +
  facet_grid(condition ~ .) + geom_vline(xintercept = 15)
```

### 3.1.3. Combined Scatter Plot

-   Setting the thresholds above for each QC metric in isolation is a valid approach, but it can result in loss of important biological variation if the different QC metrics are not visualized together to observe the population of cells that is filtered out by the independent thresholds.

-   The scatter plot below has library size on the x-axis, total number of detected features on the y-axis, and color of the points as % mitochondrial genes with the thresholds super-imposed on top.

-   From the figure, it becomes clear that the thresholds set are rather conservative, and the bulk of the data is presered with only outliers being removed.

```{r,fig.height=4, fig.width=4}
# ScatterPlot
seu@meta.data %>%
  ggplot(aes(nCount_RNA,
             nFeature_RNA,
             colour= percent.mt)) +
  geom_point() +
  labs(title = "QC Metrics Combined", 
       x = "Library Size", 
       y = "Detected Features", 
       color = "% Mitochondrial Genes") + 
  scale_color_viridis_c() + 
  facet_grid(condition ~ .) + geom_vline(xintercept = counts_thresholds) + geom_hline(yintercept = features_thresholds)
```

### 3.1.4. Cell Filtration

Here, we apply the three cell filters. This results in the removal of 455 cells, which is good enough and indicates that the thresholds being set are not too stringent on the data..

```{r}
# Classical QC
ncol(seu) #2474
seu_subset <- subset(seu, subset = (nCount_RNA > counts_thresholds[1]) & (nCount_RNA < counts_thresholds[2]) & (nFeature_RNA > features_thresholds[1]) & (nFeature_RNA < features_thresholds[2]) & (percent.mt < 15))
ncol(seu_subset) # 2019

# Saving memory
rm(seu)
```

## 3.2. Genes QC

-   This filtration step will remove all features that do not have non-zero accounts in at least 3 cells.

-   This filtration step is essential since lowly-expressed genes can come up as variable genes in subsequent steps and will skew the results of the analysis if not removed early.

```{r}
nrow(seu_subset) # 31053
filter3 <- function(seurat){
  #Threshold
  threshold <- 3
  #Raw Counts
  counts <- seurat@assays$RNA@counts
  rawcounts <- as.matrix(counts)
  #Number of cells where expression is greater than zero for each gene
  sums <- rowSums(rawcounts > 0)
  #Genes that are expressed in a number of cells greater than threshold
  sums_2 <- sums[sums > threshold]
  #Filtering and dimensions of Seurat object before and after
  seurat <- seurat[names(sums_2),]
  return(seurat)
} # function form of filter 3
seu_subset <- filter3(seurat = seu_subset)
nrow(seu_subset) # 16229
```

-   **Note:** It's important to filter first the cells and then the genes.

# 4. Cell Cycle Scoring & Assignment

-   Cell cycle is an important source of biological variation in transcriptomics data, and as such it is of great utility to assign cell cycle phase to different cells in the data based on the transcriptomic profile. Biological differences between experimental conditions can easily derive from perturbations of the cell cycle, hence the importance of this step.

-   Cell cycle phase is assigned either by pre-trained classifiers, such as the function `cyclone()` (`scran` package), or by using pre-defined gene signatures for the different phases, such as `cc.genes.updated.2019` from the Seurat package.

    -   Since we are using `Seurat` for this session, we will carry on with the later method.

-   Below, we will normalize the data first and then use the Seurat function `CellCycleScoring()` to assign cell cycle phase labels.

-   Note that the genes listed in `cc.genes.updated.2019` are for homo sapiens. We have converted these genes to their mouse equivalent in `cc.genes.mouse.rds`.

```{r}
# Normalisation, Variable Feature Selection, Data Scaling
seu_subset <- NormalizeData(seu_subset)
seu_subset <- FindVariableFeatures(seu_subset)
seu_subset <- ScaleData(seu_subset, features = rownames(seu_subset))

# Cell Cycle Features (Mouse Version)
cc.genes.mouse <- readRDS(file = "../../course_data//scRNA-Seq Module/cc.genes.mouse.rds")

# Cell Cycle Scoring
seu_subset <- CellCycleScoring(seu_subset, 
                        s.features = cc.genes.mouse$s.genes, 
                        g2m.features = cc.genes.mouse$g2m.genes, 
                        set.ident = TRUE)

table(seu_subset$Phase)
```

# 5. SCTransform

-   We have already normalized our data in section 4 prior to cell cycle scoring, but we can have multiple versions of normalized data in the same Seurat object. This can be useful as different versions of normalized data might be used for different parts of the downstream analysis.

-   Here, we will use data normalized with [**SCTransform**](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1) for visualisation and clustering; `SCTransform` has become the standard for normalisation, variable feature selection, and scaling in seurat, and its results are going to be crucial for subsequent steps in the pipeline.

```{r}
# SCTransform
seu_subset <- suppressWarnings(SCTransform(object = seu_subset, variable.features.n = 3000))
```

Notice at this point we have two assays in our data. The active assay is **SCT** **(SCTransform-Normalized data)**.

```{r}
# Available Assays
seu_subset@assays

# Active Assay
seu_subset@active.assay
```

# 6. Dimensionality Reduction

## 6.1. Principal Component Analysis (PCA)

-   The first dimensionality reduction step is PCA. PCA will help us understand the primary sources of variation in the data (be it biological or technical), and is essential for subsequent UMAP dimensionality reduction.

-   PCA is also a good QC step that might point to systematic biases.

```{r, fig.height=4, fig.width=4}
# PCA
seu_subset <- RunPCA(seu_subset)

# Visualisation
do_DimPlot(seu_subset, group.by = "Phase", plot.title = "Phase")
do_DimPlot(seu_subset, group.by = "batch", plot.title = "Batch")
do_DimPlot(seu_subset, group.by = "condition", plot.title = "Condition")
```

### 6.1.1. Checking for Technical Variation

-   As already mentioned, PCA is an excellent QC step in and within itself because we could visualise potential technical sources of variation in the data, which we would then need to regress out to uncover the primary drivers of biological variation.

-   Here, we will be plotting library size, total number of features, percentage mitochondrial genes, and batch against PCs 1-2 to see if these technical factors are a significant driver of the variation in the data. We will also be plotting cell cycle phase as well as our experimental condition of interest.

```{r, fig.height=4, fig.width=4}
# Technical Factors
## Library Size
do_FeaturePlot(seu_subset, 
        reduction = "pca", 
        features = "nCount_RNA", 
        dims = c(1,2),
        viridis_color_map = "B",
        viridis_direction = -1)

## Total Number of Features
do_FeaturePlot(seu_subset, 
        reduction = "pca", 
        features = "nFeature_RNA", 
        dims = c(1,2),
        viridis_color_map = "B",
        viridis_direction = -1)

## Percentage MT
do_FeaturePlot(seu_subset, 
        reduction = "pca", 
        features = "percent.mt", 
        dims = c(1,2),
        viridis_color_map = "B",
        viridis_direction = -1)

## Cell Cycle Phase
do_DimPlot(seu_subset, 
           reduction = "pca", 
           dims = c(1,2), 
           group.by = "Phase")

## Batch
do_DimPlot(seu_subset, 
           dims = c(1,2), 
           group.by = "batch")


```

-   From the above figures, we notice the following:

    -   Technical factors are not the primary sources of variation in the data.

    -   There is a strong cell cycle effect along PC1.

### 6.1.2. Condition of Interest

-   Here, we check for the PCs along which the primary source of variation is our condition of interest. In this case, it seems to be the case that our condition of interest is the primary source of variation along PC6.

-   This result is not surprising given the dominant effect of the cell cycle on the variation in the data, so that is why the next section will take care of cell cycle regression before proceeding with subsequent steps in the analysis.

```{r, fig.height=4, fig.width=4}
## Condition
do_DimPlot(seu_subset, 
        reduction = "pca", 
        dims = c(1,2), 
        group.by = "condition")

do_DimPlot(seu_subset, 
        reduction = "pca", 
        dims = c(2,3), 
        group.by = "condition")

do_DimPlot(seu_subset, 
        reduction = "pca", 
        dims = c(3,4), 
        group.by = "condition")

do_DimPlot(seu_subset, 
        reduction = "pca", 
        dims = c(4, 5), 
        group.by = "condition")

do_DimPlot(seu_subset, 
        reduction = "pca", 
        dims = c(5,6), 
        group.by = "condition")
```

### 6.1.3. Cell Cycle Regression

-   Given that the focus of this analysis is not cell cycle-driven variation, we will regress out cell cycle variation using `SCTransform()`, as is shown in the code below. We then run PCA on the updated count matrices and re-do the visualisations to ensure that cell cycle variation is no longer a primary driver.

```{r, fig.height=4, fig.width=4}
# SCTransform (Cell Cycle Regression)
seu_subset <- suppressWarnings(SCTransform(object = seu_subset, 
                                           variable.features.n = 3000, 
                                           vars.to.regress = "Phase"))
# PCA
seu_subset <- RunPCA(seu_subset, 
              features = VariableFeatures(object = seu_subset), 
              verbose = FALSE)
```

-   After regression of the cell cycle above, the subsequent visualisations show the following:

    -   PC1 is no longer driven by cell cycle anymore.

    -   PC5 is now driven by our experimental condition.

```{r, fig.height=4, fig.height=4}
# Visualisation
do_DimPlot(seu_subset, 
           reduction = "pca", 
           dims = c(1,2), 
           group.by = "Phase")

do_DimPlot(seu_subset, 
        reduction = "pca", 
        dims = c(4,5), 
        group.by = "condition")
```

### 6.1.4. Elbow Plot

-   The next step in the pipeline is non-linear dimensionality reduction in the form of UMAP. UMAP uses PCs as its features.

-   To define the optimal number of PCs to include for UMAP, an elbow plot is used to identify the threshold for PCA beyond which PCs are no longer representing any significant variation and are likely dominated by technical variance.

```{r}
# Elbow Plot
ElbowPlot(seu_subset, 
          ndims = 40)
pcs_use <- 1:20
```

## 6.2. UMAP

### 6.2.1. UMAP Run

```{r}
# UMAP
seu_subset <- RunUMAP(seu_subset, 
                      dims = pcs_use)
```

### 6.2.2. UMAP Results Visualisation

```{r, fig.height=6, fig.width=7}
# Visualisation
## Experimental Condition
do_DimPlot(seu_subset, 
           reduction = "umap", 
           group.by = "condition")

## Cell Cycle Phase
do_DimPlot(seu_subset, 
           reduction = "umap", 
           group.by = "Phase")
```

# 7. Clustering

## 7.1. Louvain Clustering (Multiple Resolutions)

-   The next step in the analysis pipeline is clustering analysis; clustering helps identify clusters in the data that correspond to different forms of variation, and they could then be used as the basis for differential expression analysis to understand the biology underlying the variation in the data.

-   Seurat uses community detection algorithms for clustering, namely louvain and leiden. For more information on these algorithms, please check [**here**](https://www.nature.com/articles/s41598-019-41695-z#:~:text=Unlike%20the%20Louvain%20algorithm%2C%20the,moved%20to%20a%20different%20community.).

-   Clustering below relies on PCA, and the top 20 PCs are again the input to the clustering algorithm. The louvain algorithm requires a resolution parameter, which is essential to fine-tune the extent of clustering in the data; low resolution values result in under-clustering, and high values result in over-clustering.

    -   To remedy this issue, we compute clustering results using different resolution values ranging from 0 to 1, and we visualise these results using clustering trees. Clustering trees will be explained in the next section

```{r}
for(i in seq(0,1,0.1)){
seu_subset <- seu_subset %>%
  FindNeighbors(reduction = "pca",
                dims = 1:20,
                verbose = F) %>%
  FindClusters(resolution = i,
               verbose = F)
}
```

## 7.2. Clustering Trees

-   Clustering analysis is used in many contexts to group similar samples. One problem when conducting this kind of analysis is how many clusters to use. This is usually controlled by a parameter provided to the clustering algorithm, such as $k$ for $k$-means clustering.

-   Statistics designed to help you make this choice typically either compare two clusterings or score a single clustering. A clustering tree is different in that it visualizes the relationships between at a range of resolutions.

-   To build a clustering tree we need to look at how cells move as the clustering resolution is increased. Each cluster forms a node in the tree and edges are constructed by considering the cells in a cluster at a lower resolution (say $k = 2$) that end up in a cluster at the next highest resolution (say $k = 3$).

-   By connecting clusters in this way we can see how clusters are related to each other, which are clearly distinct and which are unstable.

-   Extra information about the cells in each node can also be overlaid in order to help make the decision about which resolution to use. For more information about clustering trees please refer to the main publication [**here**](https://academic.oup.com/gigascience/article/7/7/giy083/5052205).

-   Based on the results of the clustering trees, the final clustering resolution we are going with is 0.2, which gives us a total of 3 clusters.

```{r, fig.height=10, fig.width=15}
#Clustering Tree (with resolutions)
c1 <- clustree::clustree(x = seu_subset) + 
  guides(edge_colour = FALSE, edge_alpha = FALSE) +
  theme(legend.position = "bottom")

#Clustering Tree (with SC3 Stability Index)
c2 <- clustree::clustree(x = seu_subset, 
                         node_colour = "sc3_stability") + 
  guides(edge_colour = FALSE, edge_alpha = FALSE) +
  theme(legend.position = "bottom") + 
  scale_color_viridis_c(option = "B")
c1 + c2

# Final Clustering Resolution
seu_subset <- seu_subset %>%
  FindNeighbors(reduction = "pca",
                dims = 1:20,
                verbose = F) %>%
  FindClusters(resolution = 0.2,
               verbose = F)
```

## 7.2. Clustering Results Visualisation

-   A comparison of the condition and clusters clearly shows the following:

    -   Clusters 1 and 2 are WT clusters.

    -   Cluster 0 is a SCRAMBLED cluster.

```{r, fig.height=6, fig.width=7}
p1 <- do_DimPlot(seu_subset, 
           reduction = "umap", 
           group.by = "seurat_clusters",
           label = T)
p2 <- do_DimPlot(seu_subset, 
           reduction = "umap", 
           group.by = "condition",
           label = T)
p1 + p2
```

# 8. Feature Plots & Violin Plots

-   Feature plots and violin plots are excellent visualisations to explore biological features of interest that we hypothesize could be driving the variation in our data.

-   Here, we notice **Hoxc8** being deferentially expressed in SCRAMBLED cells, and **Gstp1** in WT cells (in particular WT cells in cluster 1).

```{r fig.height=10, fig.width=20}
# Feature Plots
do_FeaturePlot(sample = seu_subset, 
            features = c("Fos", "Gria3", "Junb", "Trap1a", "Gstp1", "Nap1l5"), 
            reduction = "umap", 
            ncol = 3,
            viridis_direction = -1, 
            viridis_color_map = "B")

# Violin Plots
VlnPlot(seu_subset, 
        features = c("Fos", "Gria3", "Junb", "Trap1a", "Gstp1", "Nap1l5"), 
        ncol = 3, group.by = "condition", 
        pt.size = 0.001, 
        assay = "RNA")
```

# 9. Differential Expression Analysis (DEA)

-   The final step in the standard processing pipeline is DEA analysis. This is important to identify the biological features driving the variation between your factors of interest.

-   In this analysis, we are interested in DEA markers for our clusters as well as DEA results for WT vs SCRAMBLED.

```{r}
# Cluster Markers
ClusterMarkers <- FindAllMarkers(object = seu_subset,
                                 logfc.threshold = 0.25,
                                 min.pct = 0.25) %>% dplyr::filter(p_val_adj < 0.05)
# Condition Markers
ConditionMarkers <- FindMarkers(object = seu_subset,
                                ident.1 = "SCRAMBLED", 
                                ident.2 = "WT",
                                group.by = "condition",
                                logfc.threshold = 0.25, 
                                min.pct = 0.25) %>% dplyr::filter(p_val_adj < 0.05)
```

# Session Information

-   This is standard practice to include, and it is very good for troubleshooting potential errors with the package versions and/or the code.

-   The `sessionInfo()` includes information about the version of R used, the packages loaded in, and their current version.

```{r}
sessionInfo()
```
